#!/bin/bash
# ch-test-scope: standard

# Build an Alpine Linux image using Buildah and umoci. This file may be
# removed if/when we can support Buildah instead of Docker for the full test
# suite (#184).
#
# See Build.skopeo-umoci for some caveats also relevant here.
#
# There are three basic approaches we considered:
#
#   1. "buildah export". The main problem here is that the subcommand does not
#      exist, though it used to [1,2]. A secondary issue is that it required
#      starting up a container [3], which we don't want.
#
#   2. "podman export". Podman (formerly kpod) is a container runtime [4]; it
#      can create a container and then export its filesystem. The addition of
#      the export command is why "buildah export" was removed [2]. We haven't
#      looked into this in detail. It appears to be Buildah's recommended
#      approach but would add a dependency.
#
#   3. Export to OCI image with "buildah push", flatten with umoci, and then
#      tar up the resulting rootfs. The advantage here is that it uses only
#      documented commands; the downside is that it introduces a redundant
#      unpack/repack of tarballs
#
#   4. Build with "buildah bud --squash", export to OCI image with "buildah
#      push", and manually copy out the tarball of the single layer. The main
#      advantage is that we can do it with Buildah only; the disadvantages are
#      (1) parsing JSON in shell is a kludge and (2) it only works with
#      single-layer images. The latter is easy to get with --squash, but if
#      you have a multi-layer image, that will require some fooling around
#      that I'm pretty sure is possible but haven't figured out yet.
#
# For now, this script uses approach 4.
#
# [1]: https://github.com/containers/buildah/pull/170
# [2]: https://github.com/containers/buildah/pull/245
# [3]: https://github.com/containers/buildah/issues/1118
# [4]: https://www.projectatomic.io/blog/2018/02/reintroduction-podman

set -e

srcdir=$1
tarball=${2}.tar.gz
workdir=$3

tag=alpine39

cd "$srcdir"
export PATH=$srcdir/../bin:$PATH

if ( ! command -v buildah >/dev/null 2>&1 ); then
    echo 'buildah not found' 1>&2
    exit 65
fi

# Build image in Buildah local storage. Notes:
#
# - This hangs after "Storing signatures" if $PWD is not $srcdir.
# - Adding "--squash" makes layer caching not work.
#
#--userns-uid-map '0:999:1' --userns-gid-map '0:888:1' \

# --root "${workdir}/storage" --runroot "${workdir}/runroot" \
#BUILDAH_ISOLATION=rootless
buildah build-using-dockerfile \
        --build-arg HTTP_PROXY="$HTTP_PROXY" \
        --build-arg HTTPS_PROXY="$HTTPS_PROXY" \
        --build-arg NO_PROXY="$NO_PROXY" \
        --build-arg http_proxy="$http_proxy" \
        --build-arg https_proxy="$https_proxy" \
        --build-arg no_proxy="$no_proxy" \
        --runtime ch-run-oci \
        --layers=true -t $tag -f ./Dockerfile.${tag} . < /dev/null

cd "$workdir"

# Possible workflows to create a tarball:
#
#   1. "buildah commit --squash", then "push". This gives a tarball rather
#      than a directory; the latter better supports SquashFS.
#
#   2. "buildah inspect --format='{{.OCIv1.RootFS}}'" gives us the root
#      filesystem hash but we'd have to find the rest of its path somehow.
#
#   3. "buildah mount" and "unmount". This gives a directory but requires
#      wrapping everything with "buildah unshare".
#
# Currently we do #3.

echo "starting Buildah container"
container=$(buildah from $tag)

# On my development box, the container rootfs is accessible from the host
# (i.e., without "buildah unshare"), but I'm guessing that depends on the
# storage driver, so we use "unshare" per "buildah mount" complaints.
buildah unshare -- /bin/sh /dev/stdin <<EOF
rootfs=\$(buildah mount $container)
echo "container root: \$rootfs"
cd \$rootfs && tar czf "$tarball" .
buildah umount $container > /dev/null
EOF

echo "stopping Buildah container"
buildah rm "$container" > /dev/null
